
#when a large value of lambda is used, as compared to when a small value is used.
ridge.mod$lambda[50] # grid[50] = 11497.57
e
coef(ridge.mod)[,50] # corresponding coefficients
sqrt(sum(coef(ridge.mod)[-1,50]^2)) # l2 norm
#60 ESIMO VALORE DI LAMBDA
ridge.mod$lambda[60] # lambda = 705.48
ridge.mod$lambda[60] # lambda = 705.48
coef(ridge.mod)[,60] # corresponding coefficients
sqrt(sum(coef(ridge.mod)[-1,60]^2)) # l2 norm > l2 for lambda[50]
# obtain the ridge regression coefficients for a new lambda, say 50:
predict(ridge.mod,s=50,type="coefficients")[1:20,]
# obtain the ridge regression coefficients for a new lambda, say 50:
predict(ridge.mod,s=50,type="coefficients")[1:20,]
# obtain the ridge regression coefficients for a new lambda, say 50:
predict(ridge.mod,s=50,type="coefficients")[1:9,]
# obtain the ridge regression coefficients for a new lambda, say 50:
predict(ridge.mod,s=50,type="coefficients")[1:10,]
# obtain the ridge regression coefficients for a new lambda, say 50:
predict(ridge.mod,s=50,type="coefficients")[1:12,]
# obtain the ridge regression coefficients for a new lambda, say 50:
predict(ridge.mod,s=50,type="coefficients")[1:11,]
# Validation approach to estimate test error
set.seed(1)
train=sample(1:nrow(x), nrow(x)/2) # another typical approach to sample
test=(-train)
y.test=y[test]
# fit a ridge regression model on the training set, and evaluate its MSE on the test set, using lambda = 4.
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid,thresh=1e-12)
ridge.pred=predict(ridge.mod,s=4,newx=x[test,]) # Note the use of the predict() function again. This time we get predictions for a test set, by replacing type="coefficients" with the newx argument.
mean((ridge.pred-y.test)^2) # test MSE
mean((mean(y[train ])-y.test)^2) # test MSE, if we had instead simply fit a model with just an intercept, we would have predicted each test observation using the mean of the training observations.
# Validation approach to estimate test error
set.seed(1)
train=sample(1:nrow(x), nrow(x)/2) # another typical approach to sample
test=(-train)
y.test=y[test]
# fit a ridge regression model on the training set, and evaluate its MSE on the test set, using lambda = 4.
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid,thresh=1e-12)
ridge.pred=predict(ridge.mod,s=4,newx=x[test,]) # Note the use of the predict() function again. This time we get predictions for a test set, by replacing type="coefficients" with the newx argument.
mean((ridge.pred-y.test)^2) # test MSE
mean((mean(y[train ])-y.test)^2) # test MSE, if we had instead simply fit a model with just an intercept, we would have predicted each test observation using the mean of the training observations.
library(glmnet)
library(glmnet)
attach(tr_s)
attach(tr_s)
data_complete <- read.csv("dataset/data_complete.csv", header=TRUE)
head(data_complete)
names(data_complete)
install.packages('caTools')
library(caTools)

fuel_type + extra_urban_metric + noise_level, data = tr_s, method = "lm",
trControl = train.control)
install.packages("ggplot2")
library(caret)
install.packages("scales")
install.packages("scales")
library(caret)
install.packages('caret', dependencies = TRUE)
train.control <- trainControl(method = "cv", number = 10)
model_validation <- train(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + extra_urban_metric + noise_level, data = tr_s, method = "lm",
trControl = train.control)
setwd("~/GitHub/SDA")
library(corrplot)
library(caTools)
library(tidyverse)
library(caret)
data_complete <- read.csv("dataset/data_complete.csv", header=TRUE)
head(data_complete)
names(data_complete)

my_data <- data_complete[,c(3,7,8,9,10,11,12,13,14,15,16)]
split = sample.split(my_data$co2_emission, SplitRatio = 0.8)
tr_s = subset(my_data, split == TRUE)
t_s = subset(my_data, split == FALSE)

fit.linear <- (co2_emission ~ euro_standard + fuel_cost_6000_miles + fuel_type + engine_capacity + year + transmission_type
+ noise_level + combined_metric + urban_metric + extra_urban_metric)
x = model.matrix(fit.linear, tr_s)[,-1] #[-1] means no intercept
y = tr_s$co2_emission
grid=10^seq(10,-2,length=100) # Lambda values grid (from 10^10 to 10^-2)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
#Associated with each value of lambda is a vector of ridge regression
#coefficients, stored in a matrix that can be accessed by coef(),
#in this case 12x100, 11+intercept for each lambda value:
dim(coef(ridge.mod))
# We expect the coefficient estimates to be much smaller, in terms of l2 norm,
#when a large value of lambda is used, as compared to when a small value is used.
ridge.mod$lambda[50] # grid[50] = 11497.57
coef(ridge.mod)[,50] # corresponding coefficients
sqrt(sum(coef(ridge.mod)[-1,50]^2)) # l2 norm = 0.33 (DISTANZA DA 0)
#60 ESIMO VALORE DI LAMBDA
ridge.mod$lambda[60] # lambda = 705.48
# We expect the coefficient estimates to be much smaller, in terms of l2 norm,
#when a large value of lambda is used, as compared to when a small value is used.
ridge.mod$lambda[50] # grid[50] = 11497.57
coef(ridge.mod)[,50] # corresponding coefficients
sqrt(sum(coef(ridge.mod)[-1,50]^2)) # l2 norm = 0.33 (DISTANZA DA 0)
#60 ESIMO VALORE DI LAMBDA
ridge.mod$lambda[60] # lambda = 705.48
coef(ridge.mod)[,60] # corresponding coefficients
sqrt(sum(coef(ridge.mod)[-1,60]^2)) # l2 norm > l2 for lambda[50]
# obtain the ridge regression coefficients for a new lambda, say 50:
predict(ridge.mod,s=50,type="coefficients")[1:11,]
# Validation approach to estimate test error
set.seed(1)
train=sample(1:nrow(x), nrow(x)/2) # another typical approach to sample
test=(-train)
y.test=y[test]
# fit a ridge regression model on the training set, and evaluate its MSE on the test set, using lambda = 4.
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid,thresh=1e-12)
ridge.pred=predict(ridge.mod,s=4,newx=x[test,]) # Note the use of the predict() function again. This time we get predictions for a test set, by replacing type="coefficients" with the newx argument.
mean((ridge.pred-y.test)^2) # test MSE
mean((mean(y[train ])-y.test)^2) # test MSE, if we had instead simply fit a model with just an intercept, we would have predicted each test observation using the mean of the training observations.
ridge.pred=predict(ridge.mod,s=10,newx=x[test,]) # Note the use of the predict() function again. This time we get predictions for a test set, by replacing type="coefficients" with the newx argument.
mean((ridge.pred-y.test)^2) # test MSE = 57
mean((mean(y[train ])-y.test)^2) # test MSE, if we had instead simply fit a model with just an intercept, we would have predicted each test observation using the mean of the training observations.
ridge.pred=predict(ridge.mod,s=2,newx=x[test,]) # Note the use of the predict() function again. This time we get predictions for a test set, by replacing type="coefficients" with the newx argument.
mean((ridge.pred-y.test)^2) # test MSE = 57
mean((mean(y[train ])-y.test)^2) # test MSE, if we had instead simply fit a model with just an intercept, we would have predicted each test observation using the mean of the training observations.
# fit a ridge regression model on the training set, and evaluate its MSE on the test set, using lambda = 4.
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid,thresh=1e-12)
ridge.pred=predict(ridge.mod,s=2,newx=x[test,]) # Note the use of the predict() function again. This time we get predictions for a test set, by replacing type="coefficients" with the newx argument.
mean((ridge.pred-y.test)^2) # test MSE = 57
mean((mean(y[train ])-y.test)^2) # test MSE, if we had instead simply fit a model with just an intercept, we would have predicted each test observation using the mean of the training observations.
# fit a ridge regression model on the training set, and evaluate its MSE on the test set, using lambda = 4.
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid,thresh=1e-12)
ridge.pred=predict(ridge.mod,s=10^10,newx=x[test,]) # Note the use of the predict() function again. This time we get predictions for a test set, by replacing type="coefficients" with the newx argument.
mean((ridge.pred-y.test)^2) # test MSE = 57
mean((mean(y[train ])-y.test)^2) # test MSE, if we had instead simply fit a model with just an intercept, we would have predicted each test observation using the mean of the training observations.
# Least squares is simply ridge regression with lambda=0;
ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T,x=x[train,],y=y[train]) # corrected according to errata (glmnet pack updated)
# PREDICTION WITH LAMBDA=, CORRESPONDING TO OLS
ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T,x=x[train,],y=y[train]) # corrected according to errata (glmnet pack updated)
mean((ridge.pred-y.test)^2)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
lm(y ~ x, subset=train)
set.seed (1)
cv.out=cv.glmnet(x[train,],y[train],alpha=0)
plot(cv.out)
cv.out=cv.glmnet(x[train,],y[train],alpha=0)
dev.new()
plot(cv.out)
bestlam=cv.out$lambda.min;
bestlam;
log(bestlam) # the best lambda (212 on the text)
log(bestlam) # 1,72
cv.out$lambda.1se
ridge.pred=predict(ridge.mod,s=bestlam ,newx=x[test,])
mean((ridge.pred-y.test)^2)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
log(bestlam) # 1,72
s
set.seed (1)
cv.out=cv.glmnet(x[train,],y[train],alpha=0)
dev.new()
plot(cv.out)
bestlam=cv.out$lambda.min;
bestlam; #5,59
log(bestlam) # 1,72
cv.out$lambda.1se
ridge.pred=predict(ridge.mod,s=bestlam ,newx=x[test,])
bestlam=cv.out$lambda.min;
bestlam; #5,59
log(bestlam) # 1,72
cv.out$lambda.1se
ridge.pred=predict(ridge.mod,s=bestlam ,newx=x[test,])
mean((ridge.pred-y.test)^2)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
ridge.pred=predict(ridge.mod,s=bestlam ,newx=x[test,])
mean((ridge.pred-y.test)^2)
# PREDICTION WITH LAMBDA= 0, CORRESPONDING TO LEAST SQUARE
ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T,x=x[train,],y=y[train]) # corrected according to errata (glmnet pack updated)
mean((ridge.pred-y.test)^2) #51.47307
# fit a ridge regression model on the training set, and evaluate its MSE on the test set, using lambda = 4.
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid,thresh=1e-12)
ridge.pred=predict(ridge.mod,s=4,newx=x[test,]) # Note the use of the predict() function again. This time we get predictions for a test set, by replacing type="coefficients" with the newx argument.
mean((ridge.pred-y.test)^2) # test MSE = 57
mean((ridge.pred-y.test)^2) # test MSE = 87,90
mean((mean(y[train ])-y.test)^2) # test MSE, if we had instead simply fit a model with just an intercept, we would have predicted each test observation using the mean of the training observations.
# PREDICTION WITH LAMBDA= 10^10 , CORRESPONDING TO MODEL WITH ONLY INTERCEPT
ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])
mean((ridge.pred-y.test)^2) #  3229.959
# PREDICTION WITH LAMBDA= 0, CORRESPONDING TO LEAST SQUARE
ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T,x=x[train,],y=y[train]) # corrected according to errata (glmnet pack updated)
mean((ridge.pred-y.test)^2) #51.47307
set.seed (1)
cv.out=cv.glmnet(x[train,],y[train],alpha=0)
dev.new()
plot(cv.out)
bestlam=cv.out$lambda.min;
bestlam; #5.598393
log(bestlam) # 1.72248
cv.out$lambda.1se
ridge.pred=predict(ridge.mod,s=bestlam ,newx=x[test,])
mean((ridge.pred-y.test)^2)
bestlam=cv.out$lambda.min;
bestlam; #5.598393
log(bestlam) # 1.72248
cv.out$lambda.1se
ridge.pred=predict(ridge.mod,s=bestlam ,newx=x[test,])
mean((ridge.pred-y.test)^2)
out=glmnet(x,y,alpha=0)
predict(out,type="coefficients",s=bestlam)[1:11,]
# As expected, none of the coefficients are zero
# ridge regression does not perform variable selection!
dev.new()
plot(out,label = T, xvar = "lambda")
plot(out,label = T, xvar = "lambda")
plot(out,label = T, xvar = "lambda")
legend("bottomright", lwd = 1, col = 1:6, legend = colnames(X), cex = .5)
legend("bottomright", lwd = 1, col = 1:6, legend = colnames(x), cex = .5)
plot.new()
plot(out,label = T, xvar = "lambda")
legend("bottomright", lwd = 1, col = 1:6, legend = colnames(x), cex = .5)
set.seed (1)
cv.out=cv.glmnet(x[train,],y[train],alpha=0)
dev.new()
plot(cv.out)
bestlam=cv.out$lambda.min;
bestlam; #5.598393
log(bestlam) # 1.72248
cv.out$lambda.1se
ridge.pred=predict(ridge.mod,s=bestlam ,newx=x[test,])
mean((ridge.pred-y.test)^2) #88.87  #IMPROVEMENT RESPECT LAMBDA=4
out=glmnet(x,y,alpha=0)
predict(out,type="coefficients",s=bestlam)[1:11,]
plot.new()
plot(out,label = T, xvar = "lambda")
legend("bottomright", lwd = 1, col = 1:6, legend = colnames(x), cex = .5)
lasso.mod = glmnet(x[train,], y[train], alpha=1, lambda=grid)
dev.new()
plot(lasso.mod,label = T)
dev.new()
plot(lasso.mod,label = T, xvar = "lambda")
plot(lasso.mod,label = T, xvar = "lambda")
d
plot(lasso.mod,label = T, xvar = "lambda")
plot.new()
plot(lasso.mod,label = T, xvar = "lambda")
plot.new()
plot(lasso.mod,label = T, xvar = "lambda")
plot(lasso.mod,label = T, xvar = "lambda")
# perform cross-validation
set.seed (1)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
dev.new()
plot(cv.out)
bestlam=cv.out$lambda.min; print(bestlam);print(log(bestlam))
print(cv.out$lambda.1se)
lasso.pred=predict(lasso.mod,s=bestlam ,newx=x[test,])
mean((lasso.pred-y.test)^2) # slighly larger than ridge
print(log(bestlam))
print(bestlam)
print(cv.out$lambda.1se)
lasso.pred=predict(lasso.mod,s=bestlam ,newx=x[test,])
mean((lasso.pred-y.test)^2) # slighly larger than ridge
# However, the lasso has a substantial advantage:
# 8 of the 19 coefficient estimates are exactly zero (12 on the text).
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:11,]
lasso.coef
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:11,]
lasso.coef
lasso.coef[lasso.coef!=0]
cat("Number of coefficients equal to 0:",sum(lasso.coef==0),"\n")
# compare with OLS when only selected predictors are included.
#fit.lm=lm(Salary~Hits+Walks+CRuns+CRBI+League+Division+PutOuts, data=Hitters) # 12 coeffs = 0 on the textbook
fit.lm=lm(Salary~AtBat+Hits+Walks+Years+CHmRun+CRuns+CRBI + League + Division+PutOuts+Errors, data=Hitters)
# compare with OLS when only selected predictors are included.
#fit.lm=lm(Salary~Hits+Walks+CRuns+CRBI+League+Division+PutOuts, data=Hitters) # 12 coeffs = 0 on the textbook
fit.lm=lm(fit.linear, data=tr_s)
coef(fit.lm)
fit.lm=lm(Salary~Hits+Walks+CRun data=tr_s)
fit.lm=lm(co2_emission~ extra_urban_metric, data=tr_s)
coef(fit.lm)
lasso.coef=predict(out,type="coefficients",s=0)[1:11,]
lasso.coef
fit.lm=lm(fit.linear <- (co2_emission ~ euro_standard + fuel_cost_6000_miles + fuel_type + engine_capacity + year + transmission_type
+ noise_level + combined_metric + urban_metric ), data=tr_s)
coef(fit.lm)
lasso.coef=predict(out,type="coefficients",s=0)[1:11,]
mean((lasso.pred-y.test)^2) # slighly larger than ridge #56,15
lasso.mod = glmnet(x[train,], y[train], alpha=1, lambda=grid)
dev.new()
plot(lasso.mod,label = T)
dev.new()
plot.new()
plot(lasso.mod,label = T, xvar = "lambda")
# perform cross-validation
set.seed (1)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
dev.new()
plot(cv.out)
bestlam=cv.out$lambda.min
print(bestlam) #0.10
print(log(bestlam)) #-2,20
print(cv.out$lambda.1se)
lasso.pred=predict(lasso.mod,s=bestlam ,newx=x[test,])
mean((lasso.pred-y.test)^2) # slighly larger than ridge #56,15
set.seed (1)
cv.out=cv.glmnet(x[train,],y[train],alpha=0)
dev.new()
plot(cv.out)
bestlam=cv.out$lambda.min;
bestlam; #5.598393
log(bestlam) # 1.72248
cv.out$lambda.1se
ridge.pred=predict(ridge.mod,s=bestlam ,newx=x[test,])
mean((ridge.pred-y.test)^2) #88.87  #IMPROVEMENT OF MSE RESPECT LAMBDA=4
fit.lm=lm(fit.linear <- (co2_emission ~ euro_standard + fuel_cost_6000_miles + fuel_type + engine_capacity + year + transmission_type
+ noise_level + combined_metric + urban_metric ), data=tr_s)
lm.pred=predict(fit.lm,newx=x[test,])
lm.pred=predict(fit.lm,newx=x[test,])
mean((llm.pred-y.test)^2)
mean((lm.pred-y.test)^2)
fit.lm=lm(fit.linear <- (co2_emission ~ euro_standard + fuel_cost_6000_miles + fuel_type + engine_capacity + year + transmission_type
+ noise_level + combined_metric + urban_metric + extra_urban_metric), data=tr_s)
lm.pred=predict(fit.lm,newx=x[test,])
mean((lm.pred-y.test)^2)
fit.lm=lm(fit.linear <- (co2_emission ~ euro_standard + fuel_cost_6000_miles + fuel_type + engine_capacity + year + transmission_type
+ noise_level + combined_metric + urban_metric + extra_urban_metric), data=tr_s)
y_pred = predict(fit.lm, newdata = t_s, interval = 'confidence')
lm.pred=predict(fit.lm,newx=x[test,])
mean((lm.pred-y.test)^2)
coef(fit.lm)
summary(fit.lm)
y_pred = predict(fit.lm, newdata = t_s, interval = 'confidence')
lm.pred=predict(fit.lm,newx=x[test,])
mean((lm.pred-y.test)^2)
summary(fit.lm)
y_pred = predict(fit.lm, newdata = t_s, interval = 'confidence')
lm.pred=predict(fit.lm,newx=x[test,])
mean((lm.pred-y.t_s)^2)
lm.pred=predict(fit.lm,newx=t_s)
mean((lm.pred-y.test)^2)
y.test=y[t_s]
y.test=t_s
_
lm.pred=predict(fit.lm,newx=t_s)
mean((lm.pred-y.test)^2)
mean((lm.pred-y.test)^2)
lm.pred=predict(fit.lm,newx=x[test,])
mean((lm.pred-y.test)^2)
# PREDICTION WITH LAMBDA= 0, CORRESPONDING TO LEAST SQUARE
ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T,x=x[train,],y=y[train]) # corrected according to errata (glmnet pack updated)
mean((ridge.pred-y.test)^2) #51.47307
train=sample(1:nrow(x), nrow(x)/2) # another typical approach to sample
test=(-train)
y.test=y[test]
# PREDICTION WITH LAMBDA= 0, CORRESPONDING TO LEAST SQUARE
ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T,x=x[train,],y=y[train]) # corrected according to errata (glmnet pack updated)
mean((ridge.pred-y.test)^2) #51.47307
sqrt(sum((fit.linear$residuals)^2)/36339)
sqrt(sum((fit.linear$residuals)^2)/36339)
residui<-fit.linear$residuals
# PREDICTION WITH LAMBDA= 10^10 , CORRESPONDING TO MODEL WITH ONLY INTERCEPT
ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])
mean((ridge.pred-y.test)^2) #  3229.959
sqrt(sum((fit.linear$residui)^2)/36339)
mean((ridge.pred-y.test)^2) #  3229.959
sqrt(sum((ridge.mod$residui)^2)/36339)
library(glmnet)
attach(tr_s)
data_complete <- read.csv("dataset/data_complete.csv", header=TRUE)
head(data_complete)
names(data_complete)
# PREPREOCCESSING FOR ENCODING CATEGORICAL DATA
# data_complete$Colonna = factor(data_complete$Colonna, levels = c('', '', ''),
#                               labels = c(1,2,3))
install.packages('caTools')
library(caTools)

attach(data_complete)
attach(data_complete)
my_data <- data_complete[,c(3,7,8,9,10,11,12,13,14,15,16)]
split = sample.split(my_data$co2_emission, SplitRatio = 0.8)
tr_s = subset(my_data, split == TRUE)
t_s = subset(my_data, split == FALSE)
model <- lm(co2_emission ~ ., data = tr_s)
summary(model)
confint(model, level=.95)
resid <- model_reduced_collinearity$residuals
hist(resid)
# I residui devono avere distribuzione gaussiana:
resid <- model$residuals
hist(resid)
yfit<-fitted(model)
plot(yfit, abs(resid), ylab="Residui", xlab="Fitted", main="Residui in valore assoluto vs fitted")
plot.new()
boxplot(tr_s)$co2_emission
Q <- quantile(tr_s$engine_capacity, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(tr_s$engine_capacity)
up <-  Q[2]+1*iqr # Upper Range
low<- Q[1]-1*iqr # Lower Range
eliminated<- subset(tr_s, tr_s$engine_capacity> low & tr_s$engine_capacity< up)
boxplot(eliminated)$co2_emission
Q <- quantile(eliminated$fuel_cost_6000_miles, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(eliminated$fuel_cost_6000_miles)
up <-  Q[2]+iqr # Upper Range
low<- Q[1]-iqr # Lower Range
eliminated<- subset(eliminated, eliminated$fuel_cost_6000_miles> low & eliminated$fuel_cost_6000_miles< up)
boxplot(eliminated)$co2_emission
Q <- quantile(eliminated$noise_level, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(eliminated$noise_level)
up <-  Q[2]+iqr # Upper Range
low <- Q[1]-iqr # Lower Range
eliminated<- subset(eliminated, eliminated$noise_level> low & eliminated$noise_level< up)
boxplot(eliminated)$co2_emission
model_without_outliers <- lm(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + extra_urban_metric + noise_level, data = eliminated)
summary(model_without_outliers)
res <- cor(my_data, use="pairwise.complete.obs")
round(res, 2)
dev.new()
plot.new()
dev.off()
corrplot(res, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
car::vif(model_without_outliers)
model_reduced_collinearity <- lm(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + extra_urban_metric + noise_level, data = eliminated)
summary(model_reduced_collinearity)
confint(model_reduced_collinearity, level=.95)
res <- cor(my_data, use="pairwise.complete.obs")
round(res, 2)
dev.new()
plot.new()
dev.off()
corrplot(res, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
train.control <- trainControl(method = "cv", number = 10)
model_validation <- train(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + extra_urban_metric + noise_level, data = tr_s, method = "lm",
trControl = train.control)
res <- cor(my_data, use="pairwise.complete.obs")
round(res, 2)
dev.new()
plot.new()
dev.off()
corrplot(res, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
car::vif(model_without_outliers)
model_without_outliers
summary(model_without_outliers)
View(eliminated)
eliminated<- subset(tr_s, tr_s$engine_capacity> low & tr_s$engine_capacity< up)
boxplot(eliminated)$co2_emission
Q <- quantile(eliminated$fuel_cost_6000_miles, probs=c(.25, .75), na.rm = FALSE)
##differenza del 75 esimo e del 25esimo percentile
iqr <- IQR(eliminated$fuel_cost_6000_miles)
up <-  Q[2]+iqr # Upper Range
low<- Q[1]-iqr # Lower Range
eliminated<- subset(eliminated, eliminated$fuel_cost_6000_miles> low & eliminated$fuel_cost_6000_miles< up)
boxplot(eliminated)$co2_emission
Q <- quantile(eliminated$noise_level, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(eliminated$noise_level)
up <-  Q[2]+iqr # Upper Range
low <- Q[1]-iqr # Lower Range
eliminated<- subset(eliminated, eliminated$noise_level> low & eliminated$noise_level< up)
boxplot(eliminated)$co2_emission
model_without_outliers <- lm(co2_emission ~ ., data = eliminated)
summary(model_without_outliers)
model_without_outliers <- lm(co2_emission ~ ., data = eliminated)
summary(model_without_outliers)
model_without_outliers <- lm(co2_emission ~ ., data = eliminated)
summary(model_without_outliers)
car::vif(model_without_outliers)
model_without_outliers <- lm(co2_emission ~ ., data = eliminated)
model_without_outliers <- lm(co2_emission ~ ., data = eliminated)
View(eliminated)
eliminated<- subset(tr_s, tr_s$engine_capacity> low & tr_s$engine_capacity< up)
boxplot(eliminated)$co2_emission
data_complete <- read.csv("dataset/data_complete.csv", header=TRUE)
head(data_complete)
names(data_complete)
attach(data_complete)
my_data <- data_complete[,c(3,7,8,9,10,11,12,13,14,15,16)]
split = sample.split(my_data$co2_emission, SplitRatio = 0.8)
tr_s = subset(my_data, split == TRUE)
t_s = subset(my_data, split == FALSE)
model <- lm(co2_emission ~ ., data = tr_s)
summary(model)
resid <- model$residuals
hist(resid)
yfit<-fitted(model)
plot(yfit, abs(resid), ylab="Residui", xlab="Fitted", main="Residui in valore assoluto vs fitted")
plot.new()
boxplot(tr_s)$co2_emission
Q <- quantile(View$engine_capacity, probs=c(.25, .75), na.rm = FALSE)
Q <- quantile(tr_S$engine_capacity, probs=c(.25, .75), na.rm = FALSE)
Q <- quantile(tr_s$engine_capacity, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(tr_s$engine_capacity)
up <-  Q[2]+1*iqr # Upper Range
low<- Q[1]-1*iqr # Lower Range
eliminated<- subset(tr_s, tr_s$engine_capacity> low & tr_s$engine_capacity< up)
boxplot(eliminated)$co2_emission
Q <- quantile(eliminated$fuel_cost_6000_miles, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(eliminated$fuel_cost_6000_miles)
up <-  Q[2]+iqr # Upper Range
low<- Q[1]-iqr # Lower Range
eliminated<- subset(eliminated, eliminated$fuel_cost_6000_miles> low & eliminated$fuel_cost_6000_miles< up)
boxplot(eliminated)$co2_emission
Q <- quantile(eliminated$noise_level, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(eliminated$noise_level)
up <-  Q[2]+iqr # Upper Range
low <- Q[1]-iqr # Lower Range
eliminated<- subset(eliminated, eliminated$noise_level> low & eliminated$noise_level< up)
boxplot(eliminated)$co2_emission
model_without_outliers <- lm(co2_emission ~ ., data = eliminated)
summary(model_without_outliers)
res <- cor(my_data, use="pairwise.complete.obs")
round(res, 2)
dev.new()
plot.new()
dev.off()
corrplot(res, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
car::vif(model_without_outliers)
confint(model_without_outliers, level=.95)
model_reduced_collinearity <- lm(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + fuel_cost_6000_miles  + noise_level, data = eliminated)
car::vif(model_reduced_collinearity)
model_reduced_collinearity <- lm(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + extra_urban_metric + noise_level, data = eliminated)
car::vif(model_reduced_collinearity)
train.control <- trainControl(method = "cv", number = 10)
train_control <- trainControl(method = "cv", number = 10)
library(caret)
install.packages("vctrs")
install.packages("vctrs")
library(caret)
update.packages("vctrs")
library(caret)
update.packages("vctrs")
library(caret)
install.packages("caret")
library(caret)
install.packages("vctrs")
install.packages("vctrs")
install.packages("vctrs")
install.packages("vctrs")
install.packages("vctrs")
library(caret)
library(corrplot)
library(caTools)
library(tidyverse)
library(caret)
library(ISLR)
installed.packages("tidyr")
data_complete <- read.csv("dataset/data_complete.csv", header=TRUE)
head(data_complete)
names(data_complete)
attach(data_complete)

my_data <- data_complete[,c(3,7,8,9,10,11,12,13,14,15,16)]
split = sample.split(my_data$co2_emission, SplitRatio = 0.8)
tr_s = subset(my_data, split == TRUE)
t_s = subset(my_data, split == FALSE)

install.packages("caTools")
library(glmnet)
attach(tr_s)
fit.linear <- (co2_emission ~ euro_standard + fuel_cost_6000_miles + fuel_type + engine_capacity + year + transmission_type
+ noise_level + combined_metric + urban_metric + extra_urban_metric)
x = model.matrix(fit.linear, tr_s)[,-1] #[-1] means no intercept
y = tr_s$co2_emission
grid=10^seq(10,-2,length=100) # Lambda values grid (from 10^10 to 10^-2)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
#Associated with each value of lambda is a vector of ridge regression
#coefficients, stored in a matrix that can be accessed by coef(),
#in this case 12x100, 11+intercept for each lambda value:
dim(coef(ridge.mod))
# We expect the coefficient estimates to be much smaller, in terms of l2 norm,
#when a large value of lambda is used, as compared to when a small value is used.
ridge.mod$lambda[50] # grid[50] = 11497.57
coef(ridge.mod)[,50] # corresponding coefficients
sqrt(sum(coef(ridge.mod)[-1,50]^2)) # l2 norm = 0.33 (DISTANZA DA 0)
#60 ESIMO VALORE DI LAMBDA
ridge.mod$lambda[60] # lambda = 705.48
coef(ridge.mod)[,60] # corresponding coefficients
sqrt(sum(coef(ridge.mod)[-1,60]^2)) # l2 norm = 3.82> l2 for lambda[50]
# obtain the ridge regression coefficients for a new lambda, say 50:
predict(ridge.mod,s=50,type="coefficients")[1:11,]
# Validation approach to estimate test error
set.seed(1)
train=sample(1:nrow(x), nrow(x)/2) # another typical approach to sample
test=(-train)
y.test=y[test]
# fit a ridge regression model on the training set, and evaluate its MSE on the test set, using lambda = 4.
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid,thresh=1e-12)
ridge.pred=predict(ridge.mod,s=4,newx=x[test,]) # Note the use of the predict() function again. This time we get predictions for a test set, by replacing type="coefficients" with the newx argument.
mean((ridge.pred-y.test)^2) # test MSE = 87,90
mean((ridge.pred-y.test)^2) # test MSE = 58,59
mean((mean(y[train ])-y.test)^2) # test MSE, if we had instead simply fit a model with just an intercept, we would have predicted each test observation using the mean of the training observations.
# PREDICTION WITH LAMBDA= 10^10 , CORRESPONDING TO MODEL WITH ONLY INTERCEPT
ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])
mean((ridge.pred-y.test)^2) #  3229.959
mean((ridge.pred-y.test)^2) #  3206.242
# PREDICTION WITH LAMBDA= 0, CORRESPONDING TO LEAST SQUARE
ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T,x=x[train,],y=y[train]) # corrected according to errata (glmnet pack updated)
mean((ridge.pred-y.test)^2) #51.47307
mean((ridge.pred-y.test)^2) #69,41
set.seed (1)
cv.out=cv.glmnet(x[train,],y[train],alpha=0)
dev.new()
plot(cv.out)
bestlam=cv.out$lambda.min;
bestlam; #5.598393
log(bestlam) # 1.72248
log(bestlam) # 1.726111
cv.out$lambda.1se
ridge.pred=predict(ridge.mod,s=bestlam ,newx=x[test,])
mean((ridge.pred-y.test)^2) #88.87  #IMPROVEMENT OF MSE RESPECT LAMBDA=4
mean((ridge.pred-y.test)^2) #64,23  #IMPROVEMENT OF MSE RESPECT LAMBDA=4
out=glmnet(x,y,alpha=0)
predict(out,type="coefficients",s=bestlam)[1:11,]
# As expected, none of the coefficients are zero
# ridge regression does not perform variable selection!
dev.new()
plot.new()
plot(out,label = T, xvar = "lambda")
legend("bottomright", lwd = 1, col = 1:6, legend = colnames(x), cex = .5)
lasso.mod = glmnet(x[train,], y[train], alpha=1, lambda=grid)
dev.new()
plot(lasso.mod,label = T)
dev.new()
plot.new()
plot(lasso.mod,label = T, xvar = "lambda")
# perform cross-validation
set.seed (1)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
dev.new()
plot(cv.out)
bestlam=cv.out$lambda.min
print(bestlam) #0.10
print(bestlam) #0.01563454
print(log(bestlam)) #-2,20
x = model.matrix(fit.linear, data_complete)[,-1] #[-1] means no intercept
y = data_complete$co2_emission
grid=10^seq(10,-2,length=100) # Lambda values grid (from 10^10 to 10^-2)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
#Associated with each value of lambda is a vector of ridge regression
#coefficients, stored in a matrix that can be accessed by coef(),
#in this case 12x100, 11+intercept for each lambda value:
dim(coef(ridge.mod))
# We expect the coefficient estimates to be much smaller, in terms of l2 norm,
#when a large value of lambda is used, as compared to when a small value is used.
ridge.mod$lambda[50] # grid[50] = 11497.57
coef(ridge.mod)[,50] # corresponding coefficients
sqrt(sum(coef(ridge.mod)[-1,50]^2)) # l2 norm = 0.33 (DISTANZA DA 0)
#60 ESIMO VALORE DI LAMBDA
ridge.mod$lambda[60] # lambda = 705.48
coef(ridge.mod)[,60] # corresponding coefficients
sqrt(sum(coef(ridge.mod)[-1,60]^2)) # l2 norm = 3.82> l2 for lambda[50]
# obtain the ridge regression coefficients for a new lambda, say 50:
predict(ridge.mod,s=50,type="coefficients")[1:11,]
# Validation approach to estimate test error
set.seed(1)
train=sample(1:nrow(x), nrow(x)/2) # another typical approach to sample
test=(-train)
y.test=y[test]
# fit a ridge regression model on the training set, and evaluate its MSE on the test set, using lambda = 4.
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid,thresh=1e-12)
ridge.pred=predict(ridge.mod,s=4,newx=x[test,]) # Note the use of the predict() function again. This time we get predictions for a test set, by replacing type="coefficients" with the newx argument.
mean((ridge.pred-y.test)^2) # test MSE = 58,59
mean((mean(y[train ])-y.test)^2) # test MSE, if we had instead simply fit a model with just an intercept, we would have predicted each test observation using the mean of the training observations.
# PREDICTION WITH LAMBDA= 10^10 , CORRESPONDING TO MODEL WITH ONLY INTERCEPT
ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])
mean((ridge.pred-y.test)^2) #  3206.242
# PREDICTION WITH LAMBDA= 0, CORRESPONDING TO LEAST SQUARE
ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T,x=x[train,],y=y[train]) # corrected according to errata (glmnet pack updated)
mean((ridge.pred-y.test)^2) #69,41
set.seed (1)
cv.out=cv.glmnet(x[train,],y[train],alpha=0)
dev.new()
plot(cv.out)
bestlam=cv.out$lambda.min;
bestlam; #5.618761
log(bestlam) # 1.726111
cv.out$lambda.1se
ridge.pred=predict(ridge.mod,s=bestlam ,newx=x[test,])
mean((ridge.pred-y.test)^2) #64,23  #IMPROVEMENT OF MSE RESPECT LAMBDA=4
out=glmnet(x,y,alpha=0)
predict(out,type="coefficients",s=bestlam)[1:11,]
# As expected, none of the coefficients are zero
# ridge regression does not perform variable selection!
dev.new()
plot.new()
plot(out,label = T, xvar = "lambda")
legend("bottomright", lwd = 1, col = 1:6, legend = colnames(x), cex = .5)
lasso.mod = glmnet(x[train,], y[train], alpha=1, lambda=grid)
dev.new()
plot(lasso.mod,label = T)
dev.new()
plot.new()
plot(lasso.mod,label = T, xvar = "lambda")
# perform cross-validation
set.seed (1)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
dev.new()
plot(cv.out)
bestlam=cv.out$lambda.min
print(bestlam) #0.01563454
print(log(bestlam)) #-4.158273
print(cv.out$lambda.1se)
lasso.pred=predict(lasso.mod,s=bestlam ,newx=x[test,])
mean((lasso.pred-y.test)^2)  #56,15
lasso.pred=predict(lasso.mod,s=0,newx=x[test,],exact=T,x=x[train,],y=y[train])
mean((lasso.pred-y.test)^2)
# However, the lasso has a substantial advantage:
# 1 of the 11 coefficient estimates is exactly zero (extra_urban_metric) .
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:11,]
lasso.coef
lasso.coef[lasso.coef!=0]
cat("Number of coefficients equal to 0:",sum(lasso.coef==0),"\n")

model <- lm(co2_emission ~ ., data = tr_s)
summary(model)
confint(model, level=.95)
resid <- model$residuals
hist(resid)
plot.new()
boxplot(tr_s)$co2_emission
##metodo IQR per trovare gli outlier:
## restituzione del 25 esimo e 75 esimo percentile del set di dati
Q <- quantile(tr_s$engine_capacity, probs=c(.25, .75), na.rm = FALSE)
##differenza del 75 esimo e del 25esimo percentile
iqr <- IQR(tr_s$engine_capacity)
## ci calcoliamo gli intervalli oltre i quali tutti i punti sono outlier
up <-  Q[2]+1*iqr # Upper Range
low<- Q[1]-1*iqr # Lower Range
# ==============================================================
#ELIMINAZIONE OUTLIER
# ==============================================================
eliminated<- subset(tr_s, tr_s$engine_capacity> low & tr_s$engine_capacity< up)
boxplot(eliminated)$co2_emission
Q <- quantile(eliminated$fuel_cost_6000_miles, probs=c(.25, .75), na.rm = FALSE)
##differenza del 75 esimo e del 25esimo percentile
iqr <- IQR(eliminated$fuel_cost_6000_miles)
up <-  Q[2]+iqr # Upper Range
low<- Q[1]-iqr # Lower Range
eliminated<- subset(eliminated, eliminated$fuel_cost_6000_miles> low & eliminated$fuel_cost_6000_miles< up)
boxplot(eliminated)$co2_emission
Q <- quantile(eliminated$noise_level, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(eliminated$noise_level)
up <-  Q[2]+iqr # Upper Range
low <- Q[1]-iqr # Lower Range
eliminated<- subset(eliminated, eliminated$noise_level> low & eliminated$noise_level< up)
boxplot(eliminated)$co2_emission
model_without_outliers <- lm(co2_emission ~ ., data = eliminated)
summary(model_without_outliers)
res <- cor(my_data, use="pairwise.complete.obs")
round(res, 2)
dev.new()
plot.new()
dev.off()
corrplot(res, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
car::vif(model_without_outliers)
# DOPO LE RIFLESSIONI: sono stati eliminati i regressori che presentano un VIF oltre i 10 e che sono in correlazione con altri regressori con VIF minore di 10.
model_reduced_collinearity <- lm(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + fuel_cost_6000_miles  + noise_level, data = eliminated)
summary(model_reduced_collinearity)
confint(model_reduced_collinearity, level=.95)
res <- cor(my_data, use="pairwise.complete.obs")
round(res, 2)
dev.new()
plot.new()
dev.off()
corrplot(res, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
train_control <- trainControl(method = "cv", number = 10)
model_validation <- train(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + extra_urban_metric + noise_level, data = tr_s, method = "lm",
trControl = train.control)
train.control <- trainControl(method = "cv", number = 10)
model_validation <- train(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + extra_urban_metric + noise_level, data = tr_s, method = "lm",
trControl = train.control)
summary(model_Validation)
summary(model_validation)
train.control <- trainControl(method = "cv", number = 5)
model_validation <- train(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + extra_urban_metric + noise_level, data = tr_s, method = "lm",
trControl = train.control)
summary(model_validation)
train.control <- trainControl(method = "cv", number = 5)
model_validation <- train(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + fuel_cost_6000_miles + noise_level, data = eliminated, method = "lm",
trControl = train.control)
summary(model_validation)
model_reduced_collinearity <- lm(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + combined_metric  + noise_level, data = eliminated)
summary(model_reduced_collinearity)
confint(model_reduced_collinearity, level=.95)
train.control <- trainControl(method = "cv", number = 5)
model_validation <- train(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + combined_metric + noise_level, data = eliminated, method = "lm",
trControl = train.control)
summary(model_validation)
model_reduced_collinearity <- lm(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + urban_metric  + noise_level, data = eliminated)
summary(model_reduced_collinearity)
confint(model_reduced_collinearity, level=.95)
res <- cor(my_data, use="pairwise.complete.obs")
round(res, 2)
dev.new()
plot.new()
dev.off()
corrplot(res, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
# ==============================================================
# k-FOLD CROSS VALIDATION
# ==============================================================
train.control <- trainControl(method = "cv", number = 5)
model_validation <- train(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + urban_metric + noise_level, data = eliminated, method = "lm",
trControl = train.control)
summary(model_validation)
# DOPO LE RIFLESSIONI: sono stati eliminati i regressori che presentano un VIF oltre i 10 e che sono in correlazione con altri regressori con VIF minore di 10.
model_reduced_collinearity <- lm(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + extra_urban_metric  + noise_level, data = eliminated)
summary(model_reduced_collinearity)
confint(model_reduced_collinearity, level=.95)
res <- cor(my_data, use="pairwise.complete.obs")
round(res, 2)
dev.new()
plot.new()
dev.off()
corrplot(res, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
# ==============================================================
# k-FOLD CROSS VALIDATION
# ==============================================================
train.control <- trainControl(method = "cv", number = 5)
model_validation <- train(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + extra_urban_metric + noise_level, data = eliminated, method = "lm",
trControl = train.control)
summary(model_validation)
model <- lm(co2_emission ~ ., data = tr_s)
summary(model)
train.control <- trainControl(method = "cv", number = 5)
model_validation <- train(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + fuel_cost_6000_miles + noise_level, data = eliminated, method = "lm",
trControl = train.control)
summary(model_validation)
y_pred = predict(model_validation, newdata = t_s)
y_pred
View(t_s)
View(t_s)
y_pred = predict(model_validation, newdata = t_s, interval = "predict")
y_pred
y_pred %*% c(0, -1, 1)
y_pred = predict(model_validation, newdata = t_s, interval = "prediction")
y_pred
y_pred %*% c(0, -1, 1)
summary(y_pred)
y_pred = predict(model_validation, newdata = t_s, interval = 'prediction')
summary(y_pred)
y_pred[1]
y_pred[1,1,1]
y_pred = predict(model_validation, newdata = t_s, interval = 'predict')
y_pred
summary(y_pred)
summary(y_pred[1])
y_pred = predict(model_validation, newdata = t_s[1], interval = 'predict')
y_pred = predict(model_validation, newdata = t_s, interval = 'confidence')
y_pred
summary(y_pred)
y_pred[1]
y_pred[1,]
y_pred[,1]
y_pred[c(1,1,1)]
y_pred[c(1,2,3)]
confint(y_pred)
y_pred = predict(model_validation, newdata = t_s, interval = 'confidence')
y_pred[interval]
pred.int <- predict(model_validation, interval = "prediction")
mydata <- cbind(eliminated, pred.int)
mydata
p <- ggplot(mydata, aes(speed, dist)) +
geom_point() +
stat_smooth(method = lm)
# 3. Add prediction intervals
p + geom_line(aes(y = lwr), color = "red", linetype = "dashed")+
geom_line(aes(y = upr), color = "red", linetype = "dashed")
library("ggplot2")
p <- ggplot(mydata, aes(speed, dist)) +
geom_point() +
stat_smooth(method = lm)
# 3. Add prediction intervals
p + geom_line(aes(y = lwr), color = "red", linetype = "dashed")+
geom_line(aes(y = upr), color = "red", linetype = "dashed")
p <- ggplot(mydata, aes(co2_emission, year + euro_standard + transmission_type + engine_capacity +
fuel_type + fuel_cost_6000_miles + noise_level)) +
geom_point() +
stat_smooth(method = lm)
# 3. Add prediction intervals
p + geom_line(aes(y = lwr), color = "red", linetype = "dashed")+
geom_line(aes(y = upr), color = "red", linetype = "dashed")
y_pred = predict(model_validation, newdata = t_s, interval = 'confidence')
confint(model_validation)
=============================
y_pred = predict(model_validation, newdata = t_s, interval = 'confidence')
confint(model_validation,level=.95)
print(y_pred)
plot(y_pred)
library(MASS)
step.model <- stepAIC(model_reduced_collinearity, direction = "backward", trace = FALSE)
summary(step.model)
step.model <- stepAIC(model_reduced_collinearity, direction = "both", trace = FALSE)
summary(step.model)
step.model <- stepAIC(model_reduced_collinearity, direction = "backward", trace = FALSE)
summary(step.model)
confint(step.model, level=.95)
model_reduced_collinearity <- lm(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + fuel_cost_6000_miles  + noise_level, data = eliminated)
step.model <- stepAIC(model_reduced_collinearity, direction = "backward", trace = FALSE)
summary(step.model)
confint(step.model, level=.95)
y_pred_step_model = predict(step.model, newdata = t_s, interval = 'confidence')
plot(y_pred_step_model)
y_pred_validation = predict(model_validation, newdata = t_s, interval = 'confidence')
plot(y_pred_validation)
y_pred_step_model = predict(step.model, newdata = t_s, interval = 'confidence')
plot(y_pred_step_model)
y_pred_validation = predict(model_validation, newdata = t_s, interval = 'confidence')
plot(y_pred_validation)
y_pred_step_model = predict(step.model, newdata = t_s, interval = 'confidence')
plot(y_pred_step_model)
step.model <- stepAIC(model_reduced_collinearity, direction = "backward", scope = formula(model_reduced_collinearity), trace = FALSE)
summary(step.model)
confint(step.model, level=.95)
step.model$anova
step.model <- stepAIC(model_reduced_collinearity, direction = "both", scope = formula(model_reduced_collinearity), trace = FALSE)
summary(step.model)
step.model$anova
train.control <- trainControl(method = "cv", number = 10)
model_validation <- train(co2_emission ~ year + euro_standard + transmission_type + engine_capacity +
fuel_type + fuel_cost_6000_miles + noise_level, data = eliminated, method = "lm",
trControl = train.control)
summary(model_validation)
sample(1:100, 100/2)
len(sample())
len(sample
len(sample)
mean(((mpg-predict(model_validation,eliminated))[eliminated])^2)
n = nrow(t_s)
test = sample(1:n, n/2)
mean(((mpg-predict(model_validation,t_s))[-test])^2)
n = nrow(t_s)
test = sample(1:n, n/2)
mean(((co2_emission-predict(model_validation,t_s))[-test])^2)
mean(((co2_emission-predict(y_pred_validation))[-test])^2)
mean(((co2_emission-predict(model_validation,t_s))[-test])^2)
library(ISLR)
cv.error.10 = rep(0,10)
set.seed(17)
cv.error.10 = rep(0,10)
for(i in 1:10){
glm.fit = glm(co2_emission~year + euro_standard + transmission_type + engine_capacity +
fuel_type + fuel_cost_6000_miles + noise_level, data=eliminated)
cv.error.10[i]=cv.glm(eliminated,glm.fit,K=10)$delta[1]
}
library(boot)
set.seed(17)
cv.error.10 = rep(0,10)
for(i in 1:10){
glm.fit = glm(co2_emission~year + euro_standard + transmission_type + engine_capacity +
fuel_type + fuel_cost_6000_miles + noise_level, data=eliminated)
cv.error.10[i]=cv.glm(eliminated,glm.fit,K=10)$delta[1]
}
cv.error.10
summary(model)
predictions <- model_validation %>% predict(model_validation, newdata = t_s, interval = 'confidence')
data.frame(
R2 = R2(predictions, swiss$Fertility),
RMSE = RMSE(predictions, swiss$Fertility),
MAE = MAE(predictions, swiss$Fertility)
)
predictions <- model_validation %>% predict(model_validation, newdata = t_s, interval = 'confidence')
library(dplyr)
predictions <- model_validation %>% predict(model_validation, newdata = t_s, interval = 'confidence')
data.frame(
R2 = R2(predictions, swiss$Fertility),
RMSE = RMSE(predictions, swiss$Fertility),
MAE = MAE(predictions, swiss$Fertility)
)
predictions <- model_validation %>% predict(model_validation, newdata = t_s, interval = 'confidence')
data.frame(
R2 = R2(predictions, t_s$co2_emission),
RMSE = RMSE(predictions, t_s$co2_emission),
MAE = MAE(predictions, t_s$co2_emission)
)
predictions <- model_validation %>% predict(model_validation, newdata = t_s, interval = 'confidence')
data.frame(
R2 = R2(predictions, t_s$co2_emission),
RMSE = RMSE(predictions, t_s$co2_emission),
MAE = MAE(predictions, t_s$co2_emission)
)
predictions
predictions
1:max(x)
1:max(tr_s)
car::vif(combined_model_1)
car::vif(combined_model_2)
car::vif(combined_model_3)
combined_model_1 <- lm(co2_emission ~ year + euro_standard + transmission_type +
fuel_type + urban_metric*fuel_cost_6000_miles*extra_urban_metric*combined_metric + noise_level, data = tr_s)
combined_model_2<- lm(co2_emission ~ year + euro_standard + transmission_type +
fuel_type + fuel_cost_6000_miles*combined_metric + noise_level, data = tr_s)
combined_model_3<- lm(co2_emission ~ year + transmission_type +
fuel_type + fuel_cost_6000_miles*combined_metric + noise_level, data = tr_s)
car::vif(combined_model_1)
car::vif(combined_model_2)
car::vif(combined_model_3)
car::vif(combined_model_1)
car::vif(combined_model_2)
car::vif(combined_model_3)

